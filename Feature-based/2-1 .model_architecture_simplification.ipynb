{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQrBCUI-QeMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc7b995e-e684-408f-ac80-e29b232b15eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 20 13:44:50 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8               8W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdbKTtjvQgna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab843012-08bc-489b-d9e6-7daf2aff255e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfSmMrWDHMwG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648c7b8b-798a-4064-e3e9-f2a5c0981517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.12.1)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.6 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
          ]
        }
      ],
      "source": [
        "# Colab 셀에 입력하여 실행\n",
        "!pip install librosa h5py optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 라이브러리 임포트"
      ],
      "metadata": {
        "id": "Q7UqTAOlDbAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 초기 환경 설정\n"
      ],
      "metadata": {
        "id": "Y7GBQ5IUDc_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "import h5py\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    accuracy_score,\n",
        ")\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau  # 학습률 스케줄러 임포트\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import random\n",
        "import re\n",
        "import gc\n",
        "from typing import List, Tuple, Dict, Any\n",
        "\n",
        "# Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 일반 설정\n",
        "BATCH_SIZE = 512  # 배치 크기 조정 (기존보다 증가)\n",
        "EPOCHS = 500  # 에포크 수 설정\n",
        "LEARNING_RATE = 1e-4  # 학습률 설정\n",
        "\n",
        "# 데이터 관련 설정 (Google Drive 내 경로로 변경)\n",
        "data_output_dir = \"/content/drive/MyDrive/Sonus/Feature-based\"  # 데이터 출력 디렉토리\n",
        "metadata_file = os.path.join(data_output_dir, \"metadata.json\")  # 메타데이터 파일 경로\n",
        "cache_dir = \"/content/drive/MyDrive/Sonus/Feature-based\"  # 캐시 디렉토리 설정\n",
        "os.makedirs(cache_dir, exist_ok=True)\n",
        "hdf5_file = os.path.join(cache_dir, \"preprocessed_data.h5\")  # 전처리된 데이터 저장 경로\n",
        "n_mfcc = 40  # MFCC 계수의 수 (모델 아키텍처 간소화)\n",
        "max_len = 174  # MFCC 벡터의 최대 길이\n",
        "\n",
        "# 모델 및 로그 디렉토리 설정 (Google Drive 내 경로로 변경)\n",
        "models_output_dir = \"/content/drive/MyDrive/Sonus/Feature-based/models/light\"  # 모델 저장 디렉토리\n",
        "os.makedirs(models_output_dir, exist_ok=True)\n",
        "logs_dir = \"/content/drive/MyDrive/Sonus/Feature-based/logs\"  # 로그 디렉토리\n",
        "os.makedirs(logs_dir, exist_ok=True)\n",
        "\n",
        "# ----------------------------- GPU 및 CPU 설정 -----------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"사용 중인 디바이스: {device}\\n\")\n",
        "\n",
        "# CPU 사용 제한 설정 (필요에 따라 조정 가능)\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
        "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"4\"\n",
        "os.environ[\"MKL_NUM_THREADS\"] = \"4\"\n",
        "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"4\"\n",
        "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"4\"\n",
        "torch.set_num_threads(4)\n",
        "\n",
        "# ----------------------------- 전처리 함수 정의 -----------------------------\n",
        "def sanitize_name(name: str) -> str:\n",
        "    \"\"\"\n",
        "    문자열에서 알파벳, 숫자, 언더스코어만 남기고 나머지는 제거합니다.\n",
        "\n",
        "    Args:\n",
        "        name (str): 원본 문자열.\n",
        "\n",
        "    Returns:\n",
        "        str: 정제된 문자열.\n",
        "    \"\"\"\n",
        "    return re.sub(r\"[^a-zA-Z0-9_]\", \"\", name.replace(\" \", \"_\"))\n",
        "\n",
        "\n",
        "def load_metadata(metadata_path: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    메타데이터를 로드합니다.\n",
        "\n",
        "    Args:\n",
        "        metadata_path (str): 메타데이터 파일의 경로.\n",
        "\n",
        "    Returns:\n",
        "        List[Dict[str, Any]]: 메타데이터 리스트.\n",
        "    \"\"\"\n",
        "    metadata = []\n",
        "    with open(metadata_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            metadata.append(json.loads(line))\n",
        "    return metadata\n",
        "\n",
        "\n",
        "def extract_mfcc(file_path: str, n_mfcc: int = 40, max_len: int = 174) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    오디오 파일에서 MFCC 특징을 추출합니다.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): 오디오 파일의 경로.\n",
        "        n_mfcc (int): 추출할 MFCC 계수의 수.\n",
        "        max_len (int): MFCC 벡터의 최대 길이.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: 고정된 크기의 MFCC 배열.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path, sr=None, mono=True)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        if mfcc.shape[1] < max_len:\n",
        "            pad_width = max_len - mfcc.shape[1]\n",
        "            mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode=\"constant\")\n",
        "        else:\n",
        "            mfcc = mfcc[:, :max_len]\n",
        "        return mfcc\n",
        "    except Exception as e:\n",
        "        print(f\"MFCC 추출 실패: {file_path}, 에러: {e}\")\n",
        "        return np.zeros((n_mfcc, max_len))\n",
        "\n",
        "\n",
        "def preprocess_and_save_data(\n",
        "    metadata: List[Dict[str, Any]], data_dir: str, hdf5_path: str\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    데이터 전처리 및 HDF5 파일로 저장합니다.\n",
        "\n",
        "    Args:\n",
        "        metadata (List[Dict[str, Any]]): 메타데이터 리스트.\n",
        "        data_dir (str): 오디오 데이터가 저장된 디렉토리.\n",
        "        hdf5_path (str): 저장할 HDF5 파일의 경로.\n",
        "    \"\"\"\n",
        "    total_samples = len(metadata)\n",
        "    with h5py.File(hdf5_path, \"w\") as h5f:\n",
        "        X_ds = h5f.create_dataset(\n",
        "            \"X\", shape=(total_samples, n_mfcc, max_len), dtype=np.float32\n",
        "        )\n",
        "        Y_list = []\n",
        "        for idx, data in enumerate(tqdm(metadata, desc=\"전처리 중\")):\n",
        "            sample_path = os.path.join(\n",
        "                data_dir, data[\"relative_path\"], data[\"sample_name\"]\n",
        "            )\n",
        "            mfcc = extract_mfcc(sample_path, n_mfcc, max_len)\n",
        "            X_ds[idx] = mfcc\n",
        "            instruments = data[\"instruments\"]\n",
        "            Y_list.append(instruments)\n",
        "        Y_encoded_strings = [json.dumps(instr_list) for instr_list in Y_list]\n",
        "        dt = h5py.string_dtype(encoding=\"utf-8\")\n",
        "        Y_ds = h5f.create_dataset(\n",
        "            \"Y\", data=np.array(Y_encoded_strings, dtype=object), dtype=dt\n",
        "        )\n",
        "\n",
        "\n",
        "def load_preprocessed_data(hdf5_path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    전처리된 데이터를 HDF5 파일에서 로드합니다.\n",
        "\n",
        "    Args:\n",
        "        hdf5_path (str): HDF5 파일의 경로.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, np.ndarray]: 특징 배열 X와 레이블 리스트 Y.\n",
        "    \"\"\"\n",
        "    with h5py.File(hdf5_path, \"r\") as h5f:\n",
        "        X = h5f[\"X\"][:]\n",
        "        Y = h5f[\"Y\"][:]\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "def encode_labels(Y: np.ndarray) -> Tuple[np.ndarray, MultiLabelBinarizer, List[str]]:\n",
        "    \"\"\"\n",
        "    레이블을 이진 벡터로 인코딩합니다.\n",
        "\n",
        "    Args:\n",
        "        Y (np.ndarray): 레이블 리스트 (JSON-encoded strings).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, MultiLabelBinarizer, List[str]]: 인코딩된 레이블 배열, 레이블 변환기, 모든 악기 리스트.\n",
        "    \"\"\"\n",
        "    all_instruments = set()\n",
        "    parsed_Y = []\n",
        "    for instruments in Y:\n",
        "        if isinstance(instruments, bytes):\n",
        "            instruments = instruments.decode(\"utf-8\")\n",
        "        if isinstance(instruments, str):\n",
        "            try:\n",
        "                instruments = json.loads(instruments)\n",
        "            except json.JSONDecodeError:\n",
        "                instruments = instruments.split(\",\")\n",
        "        if not isinstance(instruments, list):\n",
        "            instruments = []\n",
        "        instruments = [instr.strip() for instr in instruments if instr.strip()]\n",
        "        all_instruments.update(instruments)\n",
        "        parsed_Y.append(instruments)\n",
        "    all_instruments = sorted(list(all_instruments))\n",
        "\n",
        "    if not all_instruments:\n",
        "        print(\"경고: 모든 악기 리스트가 비어 있습니다.\")\n",
        "\n",
        "    mlb = MultiLabelBinarizer(classes=all_instruments)\n",
        "    Y_encoded = mlb.fit_transform(parsed_Y)\n",
        "    return Y_encoded, mlb, all_instruments\n",
        "\n",
        "\n",
        "def augment_batch(batch_X: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    데이터 증강을 수행합니다.\n",
        "\n",
        "    Args:\n",
        "        batch_X (torch.Tensor): 배치의 MFCC 데이터. (channels, time, frequency)\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: 증강된 배치의 MFCC 데이터.\n",
        "    \"\"\"\n",
        "    # 데이터 증강 예시 (필요에 따라 수정)\n",
        "    scale = random.uniform(0.8, 1.2)\n",
        "    batch_X = batch_X * scale\n",
        "\n",
        "    noise = torch.randn_like(batch_X) * 0.05\n",
        "    batch_X = batch_X + noise\n",
        "\n",
        "    # 주파수 마스킹\n",
        "    freq_masking = random.randint(0, n_mfcc // 10)\n",
        "    if freq_masking > 0:\n",
        "        f0 = random.randint(0, max(n_mfcc - freq_masking - 1, 0))\n",
        "        batch_X[:, :, f0 : f0 + freq_masking] = 0\n",
        "\n",
        "    # 시간 마스킹\n",
        "    time_masking = random.randint(0, max_len // 10)\n",
        "    if time_masking > 0:\n",
        "        t0 = random.randint(0, max(max_len - time_masking - 1, 0))\n",
        "        batch_X[:, t0 : t0 + time_masking, :] = 0\n",
        "\n",
        "    return batch_X\n",
        "\n",
        "# ----------------------------- 데이터셋 클래스 정의 -----------------------------\n",
        "class MFCCDataset(Dataset):\n",
        "    \"\"\"\n",
        "    MFCC 데이터를 위한 PyTorch Dataset 클래스\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X: np.ndarray, Y: np.ndarray, augment: bool = False):\n",
        "        \"\"\"\n",
        "        초기화 함수\n",
        "\n",
        "        Args:\n",
        "            X (np.ndarray): 특징 데이터.\n",
        "            Y (np.ndarray): 레이블 데이터.\n",
        "            augment (bool): 데이터 증강 여부.\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        데이터셋의 길이를 반환합니다.\n",
        "\n",
        "        Returns:\n",
        "            int: 데이터셋의 길이.\n",
        "        \"\"\"\n",
        "        return len(self.Y)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        인덱스에 해당하는 데이터를 반환합니다.\n",
        "\n",
        "        Args:\n",
        "            idx (int): 데이터 인덱스.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor]: 특징과 레이블 텐서.\n",
        "        \"\"\"\n",
        "        x = self.X[idx]\n",
        "        y = self.Y[idx]\n",
        "\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = x.transpose(0, 2, 1)  # (채널, 시간, 주파수)\n",
        "        x = torch.from_numpy(x).float()\n",
        "\n",
        "        if self.augment:\n",
        "            x = augment_batch(x)\n",
        "\n",
        "        mean = x.mean()\n",
        "        std = x.std()\n",
        "        x = (x - mean) / (std + 1e-6)\n",
        "\n",
        "        y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "# ----------------------------- 모델 정의 -----------------------------\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes: int, dropout_rate: float = 0.3):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding='same')\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding='same')\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding='same')\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # 동적으로 conv_output_size 계산\n",
        "        example_input = torch.zeros((1, 1, max_len, n_mfcc))  # 입력 예시\n",
        "        with torch.no_grad():\n",
        "            example_output = self.pool3(self.conv3(self.pool2(self.conv2(self.pool1(self.conv1(example_input))))))\n",
        "        conv_output_size = example_output.numel()\n",
        "\n",
        "        self.fc1 = nn.Linear(conv_output_size, 128)\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\n",
        "        self.output_layer = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(self.pool1(x))\n",
        "        x = self.conv2(x)\n",
        "        x = torch.relu(self.pool2(x))\n",
        "        x = self.conv3(x)\n",
        "        x = torch.relu(self.pool3(x))\n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------- 모델 학습 및 평가 함수 정의 -----------------------------\n",
        "def train_model(\n",
        "    model: nn.Module,\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    num_epochs: int,\n",
        "    device: torch.device,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    모델을 훈련합니다.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): 학습할 모델.\n",
        "        train_loader (DataLoader): 훈련 데이터 로더.\n",
        "        val_loader (DataLoader): 검증 데이터 로더.\n",
        "        criterion: 손실 함수.\n",
        "        optimizer: 옵티마이저.\n",
        "        scheduler: 학습률 스케줄러.\n",
        "        num_epochs (int): 에포크 수.\n",
        "        device (torch.device): 장치 (CPU 또는 GPU).\n",
        "    \"\"\"\n",
        "    best_val_loss = float(\"inf\")\n",
        "    patience = 8  # 조기 종료를 위한 patience 감소\n",
        "    trigger_times = 0\n",
        "    scaler = torch.amp.GradScaler()  # 혼합 정밀도 학습을 위한 GradScaler\n",
        "\n",
        "    print(\"모델 학습 시작...\\n\")\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total_correct = 0\n",
        "\n",
        "        # 훈련 단계\n",
        "        train_bar = tqdm(\n",
        "            train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] 훈련 중\", leave=False\n",
        "        )\n",
        "        for batch_X, batch_Y in train_bar:\n",
        "            batch_X = batch_X.to(device)\n",
        "            batch_Y = batch_Y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with torch.amp.autocast(\"cuda\"):  # 혼합 정밀도 학습 적용\n",
        "                outputs = model(batch_X)\n",
        "                loss = criterion(outputs, batch_Y)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item() * batch_X.size(0)\n",
        "            preds = torch.sigmoid(outputs) > 0.5  # 예측값 계산을 위해 sigmoid 적용\n",
        "            total_correct += (preds == batch_Y.bool()).sum().item()\n",
        "\n",
        "            # 배치별 손실 업데이트\n",
        "            train_bar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = total_correct / (len(train_loader.dataset) * batch_Y.size(1))  # 멀티레이블 정확도 계산\n",
        "\n",
        "        # 검증 단계\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(\n",
        "                val_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] 검증 중\", leave=False\n",
        "            )\n",
        "            for batch_X, batch_Y in val_bar:\n",
        "                batch_X = batch_X.to(device)\n",
        "                batch_Y = batch_Y.to(device)\n",
        "\n",
        "                with torch.amp.autocast(\"cuda\"):  # 혼합 정밀도 적용\n",
        "                    outputs = model(batch_X)\n",
        "                    loss = criterion(outputs, batch_Y)\n",
        "                val_loss += loss.item() * batch_X.size(0)\n",
        "                preds = torch.sigmoid(outputs) > 0.5  # 예측값 계산\n",
        "                val_correct += (preds == batch_Y.bool()).sum().item()\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(batch_Y.cpu().numpy())\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "        avg_val_acc = val_correct / (len(val_loader.dataset) * batch_Y.size(1))  # 멀티레이블 정확도 계산\n",
        "\n",
        "        # F1-score, Precision, Recall 계산\n",
        "        epoch_f1 = f1_score(all_labels, all_preds, average=\"samples\", zero_division=0)\n",
        "        epoch_precision = precision_score(\n",
        "            all_labels, all_preds, average=\"samples\", zero_division=0\n",
        "        )\n",
        "        epoch_recall = recall_score(\n",
        "            all_labels, all_preds, average=\"samples\", zero_division=0\n",
        "        )\n",
        "\n",
        "        # 에포크별 성능 지표 출력\n",
        "        tqdm.write(\n",
        "            f\"Epoch [{epoch+1}/{num_epochs}] 완료 - \"\n",
        "            f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, \"\n",
        "            f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}, \"\n",
        "            f\"Val Precision: {epoch_precision:.4f}, Val Recall: {epoch_recall:.4f}, Val F1-Score: {epoch_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        # 에포크별 학습률 출력\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        tqdm.write(f\"Epoch [{epoch+1}/{num_epochs}] 학습률: {current_lr}\")\n",
        "\n",
        "        # Early Stopping 체크 후 스케줄러 업데이트\n",
        "        if avg_val_loss < best_val_loss - 1e-5:  # 손실이 1e-5 이상 개선되었을 때만 갱신\n",
        "            best_val_loss = avg_val_loss\n",
        "            trigger_times = 0\n",
        "            save_model(\n",
        "                model,\n",
        "                os.path.join(\n",
        "                    models_output_dir, f\"best_model_light.pt\"\n",
        "                ),\n",
        "            )\n",
        "            tqdm.write(f\"--> 최고 검증 손실 기록: {best_val_loss:.4f} 저장됨.\\n\")\n",
        "        else:\n",
        "            trigger_times += 1\n",
        "            tqdm.write(f\"--> EarlyStopping 트리거 횟수: {trigger_times}/{patience}\\n\")\n",
        "            if trigger_times >= patience:\n",
        "                tqdm.write(\"Early stopping 발생. 학습 중단.\\n\")\n",
        "                break\n",
        "\n",
        "        # 학습률 스케줄러 업데이트 (Early Stopping 체크 후에 수행)\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "    tqdm.write(f\"모델 학습 완료. 최고 검증 손실: {best_val_loss:.4f}\\n\")\n",
        "\n",
        "\n",
        "def evaluate_model(\n",
        "    model: nn.Module, test_loader: DataLoader, criterion, device: torch.device\n",
        ") -> Tuple[float, float, List[float], List[float]]:\n",
        "    \"\"\"\n",
        "    모델을 평가합니다.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): 평가할 모델.\n",
        "        test_loader (DataLoader): 테스트 데이터 로더.\n",
        "        criterion: 손실 함수.\n",
        "        device (torch.device): 장치 (CPU 또는 GPU).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float, List[float], List[float]]: 테스트 손실, 정확도, 예측 값 리스트, 실제 값 리스트.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    test_correct = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_Y in test_loader:\n",
        "            batch_X = batch_X.to(device)\n",
        "            batch_Y = batch_Y.to(device)\n",
        "            with torch.amp.autocast(\"cuda\"):\n",
        "                outputs = model(batch_X)\n",
        "                loss = criterion(outputs, batch_Y)\n",
        "            test_loss += loss.item() * batch_X.size(0)\n",
        "            preds = torch.sigmoid(outputs) > 0.5  # 예측값 계산을 위해 sigmoid 적용\n",
        "            test_correct += (preds == batch_Y.bool()).sum().item()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch_Y.cpu().numpy())\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_loader.dataset)\n",
        "    avg_test_acc = test_correct / (len(test_loader.dataset) * batch_Y.size(1))  # 멀티레이블 정확도 계산\n",
        "\n",
        "    return avg_test_loss, avg_test_acc, all_preds, all_labels\n",
        "\n",
        "\n",
        "def save_model(model: nn.Module, path: str) -> None:\n",
        "    \"\"\"\n",
        "    모델을 지정된 경로에 저장합니다.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): 저장할 모델.\n",
        "        path (str): 저장할 파일 경로.\n",
        "    \"\"\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f\"모델 저장 완료: {path}\")\n",
        "\n",
        "\n",
        "def load_model(model: nn.Module, path: str, device: torch.device) -> nn.Module:\n",
        "    \"\"\"\n",
        "    모델을 지정된 경로에서 로드합니다.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): 로드할 모델 구조.\n",
        "        path (str): 모델 파일 경로.\n",
        "        device (torch.device): 장치 (CPU 또는 GPU).\n",
        "\n",
        "    Returns:\n",
        "        nn.Module: 로드된 모델.\n",
        "    \"\"\"\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    return model\n",
        "\n",
        "def predict_instruments(audio_file_path: str, model: nn.Module, instrument_list: List[str], device: torch.device, threshold: float = 0.5) -> List[str]:\n",
        "    \"\"\"\n",
        "    개별 음원의 악기를 예측합니다.\n",
        "\n",
        "    Args:\n",
        "        audio_file_path (str): 오디오 파일 경로.\n",
        "        model (nn.Module): 학습된 모델.\n",
        "        instrument_list (List[str]): 악기 이름 리스트.\n",
        "        device (torch.device): 실행 장치.\n",
        "        threshold (float): 예측 임계값 (default=0.5).\n",
        "\n",
        "    Returns:\n",
        "        List[str]: 예측된 악기 이름 리스트.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"파일 로드 중: {audio_file_path}\")\n",
        "        # MFCC 추출\n",
        "        mfcc = extract_mfcc(audio_file_path, n_mfcc=n_mfcc, max_len=max_len)\n",
        "        if mfcc.shape != (n_mfcc, max_len):\n",
        "            raise ValueError(f\"MFCC 크기가 예상 범위를 벗어남: {mfcc.shape}\")\n",
        "\n",
        "        # 배치 및 채널 차원 추가 및 전치\n",
        "        mfcc = np.expand_dims(mfcc, axis=0)  # 채널 추가\n",
        "        mfcc = np.expand_dims(mfcc, axis=0)  # 배치 추가\n",
        "        mfcc = mfcc.transpose(0, 1, 3, 2)   # (배치, 채널, 시간, 주파수)로 변환\n",
        "\n",
        "        # 텐서 변환\n",
        "        mfcc_tensor = torch.tensor(mfcc, dtype=torch.float32).to(device)\n",
        "\n",
        "        # 모델 예측\n",
        "        model.eval()\n",
        "        print(\"모델 예측 중...\")\n",
        "        with torch.no_grad():\n",
        "            outputs = model(mfcc_tensor)\n",
        "            sigmoid_outputs = torch.sigmoid(outputs).cpu().numpy()[0]  # Sigmoid 적용\n",
        "            print(\"Sigmoid Outputs:\", sigmoid_outputs)\n",
        "\n",
        "            # 임계값에 따라 이진화\n",
        "            binary_predictions = sigmoid_outputs > threshold\n",
        "            print(\"Binary Predictions:\", binary_predictions)\n",
        "\n",
        "            # 예측된 악기 이름 디코딩\n",
        "            predicted_instruments = [\n",
        "                instrument_list[i]\n",
        "                for i, is_present in enumerate(binary_predictions)\n",
        "                if is_present\n",
        "            ]\n",
        "            print(\"Predicted Instruments:\", predicted_instruments)\n",
        "        return predicted_instruments\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"예측 실패: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "# ----------------------------- 메인 실행 부분 -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # 메타데이터 로드\n",
        "    print(\"메타데이터 로드 중...\")\n",
        "    metadata = load_metadata(metadata_file)\n",
        "    print(f\"메타데이터 로드 완료: {len(metadata)} 샘플\")\n",
        "\n",
        "    # 데이터 전처리 및 저장\n",
        "    if not os.path.exists(hdf5_file):\n",
        "        print(\"데이터 전처리 시작...\")\n",
        "        preprocess_and_save_data(metadata, data_output_dir, hdf5_file)\n",
        "        print(\"데이터 전처리 및 저장 완료.\")\n",
        "    else:\n",
        "        print(\"전처리된 데이터 파일이 존재합니다. 로드합니다.\")\n",
        "\n",
        "    # 전처리된 데이터 로드\n",
        "    print(\"전처리된 데이터 로드 중...\")\n",
        "    X, Y = load_preprocessed_data(hdf5_file)\n",
        "    print(f\"전처리된 데이터 로드 완료: X shape={X.shape}, Y shape={Y.shape}\")\n",
        "\n",
        "    # 레이블 인코딩\n",
        "    print(\"레이블 인코딩 중...\")\n",
        "    Y_encoded, mlb, all_instruments = encode_labels(Y)\n",
        "    print(f\"레이블 인코딩 완료: {len(all_instruments)} 종류의 악기\")\n",
        "\n",
        "    if len(all_instruments) == 0:\n",
        "        raise ValueError(\"레이블 인코딩 실패: 악기 리스트가 비어 있습니다.\")\n",
        "\n",
        "    # 데이터셋 분할\n",
        "    print(\"데이터셋 분할 중...\")\n",
        "    X_train, X_temp, Y_train, Y_temp = train_test_split(\n",
        "        X, Y_encoded, test_size=0.2, random_state=42\n",
        "    )\n",
        "    X_val, X_test, Y_val, Y_test = train_test_split(\n",
        "        X_temp, Y_temp, test_size=0.5, random_state=42\n",
        "    )\n",
        "    print(f\"데이터셋 분할 완료:\")\n",
        "    print(f\" - 훈련 세트: {X_train.shape[0]} 샘플\")\n",
        "    print(f\" - 검증 세트: {X_val.shape[0]} 샘플\")\n",
        "    print(f\" - 테스트 세트: {X_test.shape[0]} 샘플\")\n",
        "\n",
        "    # 데이터셋 및 데이터로더 생성\n",
        "    train_dataset = MFCCDataset(X_train, Y_train, augment=True)\n",
        "    val_dataset = MFCCDataset(X_val, Y_val, augment=False)\n",
        "    test_dataset = MFCCDataset(X_test, Y_test, augment=False)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True\n",
        "    )\n",
        "\n",
        "    # 레이블과 인덱스 확인\n",
        "    for idx, instrument in enumerate(all_instruments):\n",
        "        print(f\"Index: {idx}, Instrument: {instrument}\")\n",
        "\n",
        "    # 모델 구축\n",
        "    print(\"모델 구축 중...\")\n",
        "    # 입력 데이터 크기 확인\n",
        "    input_shape = (1, max_len, n_mfcc)  # (채널, 시간, 주파수)\n",
        "    num_classes = len(all_instruments)\n",
        "    model = CNNModel(num_classes=num_classes).to(device)\n",
        "\n",
        "\n",
        "    # 옵티마이저와 손실 함수 설정\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    criterion = nn.BCEWithLogitsLoss()  # BCEWithLogitsLoss로 변경\n",
        "\n",
        "    # 학습률 스케줄러 설정\n",
        "    scheduler = ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode='min',\n",
        "        factor=0.5,\n",
        "        patience=4,  # patience를 늘려 학습률 감소 전에 더 많은 에포크를 기다림\n",
        "        verbose=True,\n",
        "        threshold=1e-5,  # 손실 개선을 감지하기 위한 임계값을 작게 설정\n",
        "        threshold_mode='abs'\n",
        "    )\n",
        "\n",
        "    # 모델 훈련\n",
        "    # print(\"모델 훈련 시작...\")\n",
        "    # train_model(\n",
        "    #     model=model,\n",
        "    #     train_loader=train_loader,\n",
        "    #     val_loader=val_loader,\n",
        "    #     criterion=criterion,\n",
        "    #     optimizer=optimizer,\n",
        "    #     scheduler=scheduler,\n",
        "    #     num_epochs=EPOCHS,\n",
        "    #     device=device,\n",
        "    # )\n",
        "    # print(\"모델 훈련 완료.\")\n",
        "\n",
        "    # 최상의 모델 로드\n",
        "    try:\n",
        "        model = load_model(\n",
        "            model,\n",
        "            os.path.join(\n",
        "                models_output_dir, f\"best_model_light.pt\"\n",
        "            ),\n",
        "            device,\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"모델 로드 중 오류 발생: {e}\")\n",
        "\n",
        "    # 모델 평가\n",
        "    print(\"모델 평가 중...\")\n",
        "    avg_test_loss, avg_test_acc, all_preds, all_labels = evaluate_model(\n",
        "        model=model, test_loader=test_loader, criterion=criterion, device=device\n",
        "    )\n",
        "    print(f\"테스트 손실: {avg_test_loss}\")\n",
        "    print(f\"테스트 정확도: {avg_test_acc}\")\n",
        "\n",
        "    # F1-score 계산\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"samples\", zero_division=0)\n",
        "    print(f\"F1-score: {f1}\")\n",
        "\n",
        "    # 분류 리포트 출력\n",
        "    report = classification_report(\n",
        "        all_labels,\n",
        "        all_preds,\n",
        "        target_names=all_instruments,\n",
        "        zero_division=0,\n",
        "    )\n",
        "    print(report)\n",
        "\n",
        "    # 예측 결과 저장\n",
        "    print(\"사용자 평가를 위한 예측 결과를 저장합니다.\")\n",
        "    predictions_array = np.array(all_preds)  # shape=(samples, instruments)\n",
        "    np.save(os.path.join(data_output_dir, \"predictions.npy\"), predictions_array)\n",
        "    print(\"예측 결과 저장 완료: predictions.npy\")\n",
        "\n",
        "\n",
        "\n",
        "    # 테스트할 개별 음원 경로\n",
        "    test_audio_path = \"/content/drive/MyDrive/Sonus/Feature-based/concerto_sample_1.mp3\"\n",
        "\n",
        "    # 모델을 사용해 예측\n",
        "    predicted_instruments = predict_instruments(\n",
        "        audio_file_path=test_audio_path,\n",
        "        model=model,\n",
        "        instrument_list=all_instruments,\n",
        "        device=device,\n",
        "        threshold=0.5  # 임계값 설정\n",
        "    )\n",
        "    print(f\"예측된 악기: {predicted_instruments}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p7IPrbZGP7T",
        "outputId": "45f533a0-9ed9-482e-b468-8464214f088a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "사용 중인 디바이스: cuda\n",
            "\n",
            "메타데이터 로드 중...\n",
            "메타데이터 로드 완료: 231980 샘플\n",
            "전처리된 데이터 파일이 존재합니다. 로드합니다.\n",
            "전처리된 데이터 로드 중...\n",
            "전처리된 데이터 로드 완료: X shape=(231980, 40, 174), Y shape=(231980,)\n",
            "레이블 인코딩 중...\n",
            "레이블 인코딩 완료: 16 종류의 악기\n",
            "데이터셋 분할 중...\n",
            "데이터셋 분할 완료:\n",
            " - 훈련 세트: 185584 샘플\n",
            " - 검증 세트: 23198 샘플\n",
            " - 테스트 세트: 23198 샘플\n",
            "Index: 0, Instrument: bass clarinet\n",
            "Index: 1, Instrument: bassoon\n",
            "Index: 2, Instrument: cello\n",
            "Index: 3, Instrument: clarinet\n",
            "Index: 4, Instrument: clash cymbals\n",
            "Index: 5, Instrument: double bass\n",
            "Index: 6, Instrument: flute\n",
            "Index: 7, Instrument: french horn\n",
            "Index: 8, Instrument: oboe\n",
            "Index: 9, Instrument: saxophone\n",
            "Index: 10, Instrument: tambourine\n",
            "Index: 11, Instrument: trombone\n",
            "Index: 12, Instrument: trumpet\n",
            "Index: 13, Instrument: tuba\n",
            "Index: 14, Instrument: viola\n",
            "Index: 15, Instrument: violin\n",
            "모델 구축 중...\n",
            "모델 평가 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "<ipython-input-13-1fce27d63a68>:530: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 손실: 0.34189200249455365\n",
            "테스트 정확도: 0.8422681912233814\n",
            "F1-score: 0.8182959508846781\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "bass clarinet       0.84      0.88      0.86     12396\n",
            "      bassoon       0.88      0.89      0.88     12471\n",
            "        cello       0.77      0.84      0.81     12391\n",
            "     clarinet       0.82      0.88      0.85     12483\n",
            "clash cymbals       1.00      0.99      0.99     12448\n",
            "  double bass       0.86      0.88      0.87     12534\n",
            "        flute       0.75      0.83      0.79     12412\n",
            "  french horn       0.78      0.85      0.81     12567\n",
            "         oboe       0.82      0.86      0.84     12488\n",
            "    saxophone       0.84      0.85      0.84     12395\n",
            "   tambourine       0.99      0.98      0.99     12391\n",
            "     trombone       0.80      0.86      0.83     12381\n",
            "      trumpet       0.82      0.85      0.83     12460\n",
            "         tuba       0.90      0.92      0.91     12383\n",
            "        viola       0.77      0.83      0.80     12371\n",
            "       violin       0.78      0.83      0.81     12461\n",
            "\n",
            "    micro avg       0.84      0.88      0.86    199032\n",
            "    macro avg       0.84      0.88      0.86    199032\n",
            " weighted avg       0.84      0.88      0.86    199032\n",
            "  samples avg       0.84      0.83      0.82    199032\n",
            "\n",
            "사용자 평가를 위한 예측 결과를 저장합니다.\n",
            "예측 결과 저장 완료: predictions.npy\n",
            "파일 로드 중: /content/drive/MyDrive/Sonus/Feature-based/concerto_sample_1.mp3\n",
            "모델 예측 중...\n",
            "Sigmoid Outputs: [9.9803466e-01 1.0000000e+00 9.9999964e-01 1.0000000e+00 1.0000000e+00\n",
            " 1.0000000e+00 3.7967458e-01 6.6669786e-04 3.1263959e-02 1.0000000e+00\n",
            " 1.6102007e-18 9.9993074e-01 1.0000000e+00 1.0000000e+00 9.9999976e-01\n",
            " 9.9999404e-01]\n",
            "Binary Predictions: [ True  True  True  True  True  True False False False  True False  True\n",
            "  True  True  True  True]\n",
            "Predicted Instruments: ['bass clarinet', 'bassoon', 'cello', 'clarinet', 'clash cymbals', 'double bass', 'saxophone', 'trombone', 'trumpet', 'tuba', 'viola', 'violin']\n",
            "예측된 악기: ['bass clarinet', 'bassoon', 'cello', 'clarinet', 'clash cymbals', 'double bass', 'saxophone', 'trombone', 'trumpet', 'tuba', 'viola', 'violin']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kK_nsuoOCA9t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}